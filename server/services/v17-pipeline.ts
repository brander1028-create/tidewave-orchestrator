/**
 * v17 Pipeline: Pre-enrich + Score-First Gate + autoFill + Auto Keyword Enrichment
 * ì™„ì „ ìë™í™”ëœ í‚¤ì›Œë“œ ê´€ë¦¬ ì‹œìŠ¤í…œ
 */
import { getAlgoConfig } from './algo-config';
import { getVolumesWithHealth } from './externals-health';
import { serpScraper } from './serp-scraper';
import { db } from '../db';
import { postTierChecks } from '../../shared/schema';
import { autoEnrichFromTitle } from './auto-keyword-enrichment';

// Import Phase2 types only (engines replaced with deterministic logic)
import { Candidate, Tier } from '../phase2/types';
import { extractTitleTokens, makeBigrams, hasMatjip, hasLocal } from './title-keyword-extractor';

// â˜… v17-deterministic: ìƒˆë¡œìš´ ì œëª© í† í° ì¶”ì¶œê¸° ì‚¬ìš©

/**
 * Decide whether to activate canary configuration based on ratio and keywords
 */
function shouldActivateCanary(inputKeyword: string, canaryConfig: any): boolean {
  if (!canaryConfig.enabled) {
    return false;
  }
  
  // If specific keywords are defined, only apply canary to those keywords
  if (canaryConfig.keywords && canaryConfig.keywords.length > 0) {
    const normalizedKeyword = inputKeyword.toLowerCase().trim();
    const isTargetKeyword = canaryConfig.keywords.some((keyword: string) => 
      normalizedKeyword.includes(keyword.toLowerCase()) || 
      keyword.toLowerCase().includes(normalizedKeyword)
    );
    
    if (!isTargetKeyword) {
      return false; // Not a target keyword, use production
    }
  }
  
  // Apply ratio-based decision
  const randomValue = Math.random();
  const shouldActivate = randomValue < canaryConfig.ratio;
  
  if (canaryConfig.keywords && canaryConfig.keywords.length > 0) {
    console.log(`ğŸ¯ [Canary] Keyword "${inputKeyword}" matched target keywords, ratio check: ${randomValue.toFixed(3)} < ${canaryConfig.ratio} = ${shouldActivate}`);
  } else {
    console.log(`ğŸ² [Canary] Ratio check: ${randomValue.toFixed(3)} < ${canaryConfig.ratio} = ${shouldActivate}`);
  }
  
  return shouldActivate;
}

export interface V17PipelineResult {
  tiers: Array<{
    tier: number;
    text: string;
    volume: number | null;
    rank: number | null;
    score: number;
    adScore?: number;
    eligible?: boolean;
    skipReason?: string;
  }>;
  stats: {
    candidatesGenerated: number;
    preEnriched: number;
    gateFiltered: number;
    tiersAutoFilled: number;
  };
}

/**
 * v17 ì™„ì „ íŒŒì´í”„ë¼ì¸: ì œëª© â†’ í›„ë³´ ìƒì„± â†’ Pre-enrich â†’ Gate â†’ ì ìˆ˜ â†’ í‹°ì–´ â†’ ìë™ë³´ê°•
 */
export async function processPostTitleV17(
  title: string,
  jobId: string,
  blogId: string,
  postId: number,
  inputKeyword: string,
  options: { deterministic?: boolean } = {}
): Promise<V17PipelineResult> {
  console.log(`ğŸš€ [v17 Pipeline] Starting for title: "${title.substring(0, 50)}..."`);
  
  // Step 0: ìë™ í‚¤ì›Œë“œ Enrichment (ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­)
  // ğŸ”’ HYBRID MODE: autoEnrichFromTitle ë¹„í™œì„±í™” (ì œëª© ì¡°í•©ë§Œ ì‚¬ìš©)
  if (process.env.HYBRID_MODE === 'true') {
    console.log(`ğŸ¯ [HYBRID MODE] Skipping autoEnrichFromTitle - using title bigrams only`);
  } else {
    console.log(`ğŸ” [v17 Pipeline] Starting auto-enrichment for title analysis`);
    try {
      const enrichmentResult = await autoEnrichFromTitle(title, inputKeyword, jobId, blogId, { deterministic: options.deterministic });
      console.log(`âœ… [v17 Pipeline] Auto-enrichment completed:`);
      console.log(`   - Found in DB: ${enrichmentResult.foundInDB.length}`);
      console.log(`   - Missing from DB: ${enrichmentResult.missingFromDB.length}`);
      console.log(`   - Newly enriched: ${enrichmentResult.newlyEnriched.length}`);
      console.log(`   - Top keyword: ${enrichmentResult.topKeyword}`);
      console.log(`   - Generated combinations: ${enrichmentResult.generatedCombinations.length}`);
      console.log(`   - Filtered ineligible: ${enrichmentResult.filteredIneligible.length}`);
      console.log(`   - Final tiers: ${enrichmentResult.finalTiers.length}`);
      console.log(`   - API calls: ${enrichmentResult.stats.apiCalls}`);
    } catch (enrichmentError) {
      console.error(`âš ï¸ [v17 Pipeline] Auto-enrichment failed, continuing with standard pipeline:`, enrichmentError);
    }
  }
  
  // Step 1: v17 í•«ë¦¬ë¡œë“œ ì„¤ì •
  const baseCfg = await getAlgoConfig();
  
  // Step 1.1: Canary System - Decide configuration to use
  let cfg = baseCfg;
  let isCanaryTraffic = false;
  
  if (baseCfg.features?.canary?.enabled === true) {
    // Check if this request should use canary configuration
    const shouldUseCanary = shouldActivateCanary(inputKeyword, baseCfg.features.canary);
    
    if (shouldUseCanary) {
      isCanaryTraffic = true;
      // Load test/canary configuration (for now, use base config with modifications)
      // In future, this could load from a separate canary config store
      cfg = {
        ...baseCfg,
        // Example: Use different engine for canary traffic
        phase2: {
          ...baseCfg.phase2,
          engine: baseCfg.phase2.engine === 'lk' ? 'hybrid' : 'lk'
        }
      };
      console.log(`ğŸ§ª [v17 Canary] ACTIVE - Using canary config for keyword "${inputKeyword}"`);
      console.log(`ğŸ§ª [v17 Canary] Engine switch: ${baseCfg.phase2.engine} â†’ ${cfg.phase2.engine}`);
    } else {
      console.log(`ğŸ“Š [v17 Canary] INACTIVE - Using production config`);
    }
  }
  
  console.log(`âš™ï¸ [v17 Pipeline] Config loaded - Deterministic Mode, Gate: ${cfg.features.scoreFirstGate ? 'ON' : 'OFF'}${isCanaryTraffic ? ' [CANARY]' : ''}`);
  
  // Step 2: â˜… ê²°ì •ë¡ ì  í† í° ì¶”ì¶œ (í‚¤ì›Œë“œ í­ì¦ ë°©ì§€)
  console.log(`ğŸ¯ [v17 Deterministic] Starting title token extraction...`);
  
  const toks = extractTitleTokens(title);
  console.log(`ğŸ“ [v17] Extracted ${toks.length} tokens: ${toks.slice(0, 5).join(', ')}...`);
  
  if (toks.length === 0) {
    console.log(`âš ï¸ [v17] No eligible tokens after filtering, using input keyword as fallback`);
    // âœ… ì…ë ¥ í‚¤ì›Œë“œë¥¼ T1ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë¹ˆ ê²°ê³¼ ë°©ì§€
    const fallbackTokens = [inputKeyword];
    console.log(`ğŸ”„ [v17 Fallback] Using input keyword "${inputKeyword}" as T1 candidate`);
    
    // fallback í† í°ìœ¼ë¡œ ì§„í–‰
    const fallbackCandidates: Candidate[] = fallbackTokens.map(tok => ({
      text: tok,
      frequency: 1,
      position: 0,
      length: tok.length,
      compound: false,
      volume: 0,
      rank: null,
      adScore: 0,
      eligible: true
    }));
    
    // T1ë§Œ ìƒì„±í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë¹ˆ ìƒíƒœë¡œ ì €ì¥
    const tiers: Tier[] = [
      {
        tier: 1,
        candidate: {
          text: inputKeyword,
          volume: 0,
          frequency: 1,
          position: 0,
          length: inputKeyword.length,
          compound: false,
          rank: null,
          adScore: 0,
          eligible: true
        },
        score: 50 // ê¸°ë³¸ ì ìˆ˜
      }
    ];
    
    // ë°ì´í„°ë² ì´ìŠ¤ì— tier ì •ë³´ ì €ì¥
    try {
      for (const tier of tiers) {
        await db.insert(postTierChecks).values({
          jobId: jobId,
          blogId: blogId,
          postId: postId.toString(),
          postTitle: title,
          inputKeyword: inputKeyword,
          tier: tier.tier,
          textSurface: tier.candidate.text,
          textNrm: tier.candidate.text,
          volume: tier.candidate.volume || null,
          rank: tier.candidate.rank || null,
          score: tier.score,
          eligible: tier.candidate.eligible || false,
          adscore: tier.candidate.adScore || null
        });
      }
      console.log(`âœ… [v17 Fallback] Saved ${tiers.length} tier to database`);
    } catch (error) {
      console.error(`âŒ [v17 Fallback] Failed to save tiers:`, error);
    }
    
    return {
      tiers: tiers.map(t => ({
        tier: t.tier,
        text: t.candidate.text,
        volume: t.candidate.volume || null,
        rank: t.candidate.rank || null,
        score: t.score,
        adScore: t.candidate.adScore || undefined,
        eligible: t.candidate.eligible || undefined
      })),
      stats: { candidatesGenerated: 1, preEnriched: 0, gateFiltered: 0, tiersAutoFilled: 0 }
    };
  }
  
  // Convert tokens to bigram candidates (ì œëª©ì—ì„œ ì“¸ ì¡°í•©ë§Œ)
  const candidates: Candidate[] = [];
  
  // í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ: bigram ì¡°í•©ë§Œ ìƒì„±
  if (process.env.HYBRID_MODE === 'true') {
    // ì œëª©ì—ì„œ bigram ì¡°í•© ìƒì„± (sliding window)
    for (let i = 0; i < toks.length - 1 && candidates.length < 4; i++) {
      const bigram = `${toks[i]} ${toks[i + 1]}`;
      candidates.push({
        text: bigram,
        frequency: 1,
        position: i,
        length: bigram.length,
        compound: true,
        volume: 0
      });
    }
    
    // ğŸ”’ HYBRID MODE: bigram ì¡°í•©ë§Œ ì‚¬ìš©, unigram í´ë°± ì—†ìŒ
    // "ì œëª©ì—ì„œ ì“¸ ì¡°í•©ë§Œ" ì›ì¹™ ì¤€ìˆ˜
    
    console.log(`ğŸ”¤ [HYBRID MODE] Generated ${candidates.length} bigram combinations from title tokens`);
  } else {
    // ê¸°ì¡´ ë¡œì§: unigram í›„ë³´ ìƒì„±
    toks.slice(0, 4).forEach(tok => {
      candidates.push({
        text: tok,
        frequency: 1,
        position: 0,
        length: tok.length,
        compound: false,
        volume: 0
      });
    });
    
    console.log(`ğŸ”¤ [v17 Pipeline] Generated ${candidates.length} deterministic candidates (max 4 to prevent explosion)`);
  }
  
  const stats = {
    candidatesGenerated: candidates.length,
    preEnriched: 0,
    gateFiltered: 0,
    tiersAutoFilled: 0,
  };
  
  // Step 3: Pre-enrich (DBâ†’APIâ†’upsertâ†’merge) - DETERMINISTIC MODE: Skip API calls
  if (cfg.features.preEnrich && !options.deterministic) {
    console.log(`ğŸ“Š [v17 Pipeline] Pre-enriching ${candidates.length} candidates`);
    
    const candidateTexts = candidates.map(c => c.text);
    try {
      const volumeData = await getVolumesWithHealth(db, candidateTexts);
    
    // Merge volumes back to candidates (ë‹¤ì¤‘ í‚¤ ì¡°íšŒë¡œ ìˆ˜ì •)
    candidates.forEach(candidate => {
      // âœ… ìˆ˜ì •: ë‹¤ì¤‘ í‚¤ ì¡°íšŒ (architect ê¶Œì¥ì‚¬í•­)
      const keyRaw = candidate.text;
      const keyLC = keyRaw.toLowerCase().trim();
      const keyNrm = keyRaw.normalize('NFKC').toLowerCase().replace(/[\s\-_.]+/g, '');
      
      const volumeInfo = volumeData.volumes[keyRaw] || 
                        volumeData.volumes[keyLC] || 
                        volumeData.volumes[keyNrm];
      
      if (volumeInfo && volumeInfo.total > 0) {
        candidate.volume = volumeInfo.total;
        stats.preEnriched++;
        console.log(`   ğŸ“Š [Pre-enrich] "${candidate.text}" â†’ volume ${volumeInfo.total}`);
      }
    });
    
      console.log(`âœ… [v17 Pipeline] Pre-enriched ${stats.preEnriched}/${candidates.length} candidates`);
    } catch (error) {
      console.error(`âŒ [v17 Pipeline] Pre-enrich failed:`, error);
    }
  } else if (cfg.features.preEnrich && options.deterministic) {
    console.log(`ğŸ¯ [DETERMINISTIC MODE] Skipping pre-enrich API calls for ${candidates.length} candidates`);
  }
  
  // Step 3.5: ì¶”ê°€ í‚¤ì›Œë“œ ë°œêµ´ (ì‚¬ìš©ì ìš”ì²­ì‚¬í•­)
  // ğŸ”’ HYBRID MODE: ì œëª© ì¡°í•©ë§Œ ì‚¬ìš©, ì—°ê´€í‚¤ì›Œë“œ ë°œêµ´ ë¹„í™œì„±í™”
  if (process.env.HYBRID_MODE === 'true') {
    console.log(`ğŸ¯ [HYBRID MODE] Skipping Step 3.5 ì¶”ê°€ í‚¤ì›Œë“œ ë°œêµ´ - title bigrams only`);
    const candidatesWithoutVolume = candidates.filter(c => !c.volume || c.volume === 0);
    if (candidatesWithoutVolume.length > 0) {
      console.log(`ğŸ”„ [HYBRID MODE] ${candidatesWithoutVolume.length}ê°œ í‚¤ì›Œë“œëŠ” ì œëª© ì¡°í•©ì—ì„œë§Œ ì¶”ì¶œëœ ìƒíƒœë¡œ ìœ ì§€`);
    }
  } else {
    // ì œëª©ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ DBì— ì—†ìœ¼ë©´ APIë¡œ ì¶”ê°€í•´ì„œ DB í™•ì¥
    console.log(`ğŸ” [v17 Pipeline] Step 3.5: ì¶”ê°€ í‚¤ì›Œë“œ ë°œêµ´ ì‹œì‘`);
    const candidatesWithoutVolume = candidates.filter(c => !c.volume || c.volume === 0);
    
    if (candidatesWithoutVolume.length > 0 && !options.deterministic) {
      console.log(`ğŸš€ [ì¶”ê°€ í‚¤ì›Œë“œ ë°œêµ´] ${candidatesWithoutVolume.length}ê°œ í‚¤ì›Œë“œë¥¼ DBì— ì¶”ê°€í•©ë‹ˆë‹¤`);
      console.log(`   í‚¤ì›Œë“œ: ${candidatesWithoutVolume.map(c => c.text).slice(0, 5).join(', ')}${candidatesWithoutVolume.length > 5 ? '...' : ''}`);
      
      try {
        const missingKeywords = candidatesWithoutVolume.map(c => c.text);
        
        // ë„¤ì´ë²„ SearchAds APIë¡œ í‚¤ì›Œë“œ ë°œêµ´ ë° DB ì¶”ê°€
        const volumeData = await getVolumesWithHealth(db, missingKeywords);
        let enrichedCount = 0;
        
        // ìƒˆë¡œ ì¶”ê°€ëœ í‚¤ì›Œë“œ ì •ë³´ë¥¼ candidatesì— ë‹¤ì‹œ merge
        candidatesWithoutVolume.forEach(candidate => {
          const keyRaw = candidate.text;
          const keyLC = keyRaw.toLowerCase().trim();
          const keyNrm = keyRaw.normalize('NFKC').toLowerCase().replace(/[\s\-_.]+/g, '');
          
          const volumeInfo = volumeData.volumes[keyRaw] || 
                            volumeData.volumes[keyLC] || 
                            volumeData.volumes[keyNrm];
          
          if (volumeInfo && volumeInfo.total > 0) {
            candidate.volume = volumeInfo.total;
            enrichedCount++;
            console.log(`   âœ… [í‚¤ì›Œë“œ ë°œêµ´] "${candidate.text}" â†’ volume ${volumeInfo.total} (DBì— ì¶”ê°€ë¨)`);
          }
        });
        
        stats.preEnriched += enrichedCount;
        console.log(`ğŸ‰ [ì¶”ê°€ í‚¤ì›Œë“œ ë°œêµ´] ì™„ë£Œ: ${enrichedCount}ê°œ í‚¤ì›Œë“œë¥¼ DBì— ì¶”ê°€í•˜ê³  volume í™•ë³´`);
        
      } catch (error) {
        console.error(`âŒ [ì¶”ê°€ í‚¤ì›Œë“œ ë°œêµ´] ì‹¤íŒ¨:`, error);
        console.log(`âš ï¸ [ì¶”ê°€ í‚¤ì›Œë“œ ë°œêµ´] API ì˜¤ë¥˜ë¡œ ì¼ë¶€ í‚¤ì›Œë“œëŠ” volume ì—†ì´ ì§„í–‰ë©ë‹ˆë‹¤`);
      }
    } else if (candidatesWithoutVolume.length > 0 && options.deterministic) {
      console.log(`ğŸ¯ [DETERMINISTIC MODE] Skipping ì¶”ê°€ í‚¤ì›Œë“œ ë°œêµ´ API calls for ${candidatesWithoutVolume.length} keywords`);
    } else {
      console.log(`âœ… [ì¶”ê°€ í‚¤ì›Œë“œ ë°œêµ´] ëª¨ë“  í‚¤ì›Œë“œê°€ ì´ë¯¸ DBì— ìˆìŠµë‹ˆë‹¤`);
    }
  }
  
  // Step 4: â˜… ê²°ì •ë¡ ì  Gate + Scoring (Phase2 ì—”ì§„ ëŒ€ì‹ )
  console.log(`ğŸš« [v17 Deterministic] Applying deterministic gate and scoring...`);
  
  // Simple scoring: volume-based with minimal adScore
  const enrichedCandidates: Candidate[] = candidates.map(candidate => {
    const vol = candidate.volume || 0;
    const volScore = vol > 0 ? Math.log10(vol) * 25 : 0;
    const adScore = 0; // No adScore in v17 deterministic mode
    const totalScore = volScore;
    
    // â˜… ê²Œì´íŠ¸ ì •ì±… ì™„í™”: í•˜ë“œì»· ì œê±°, í´ë°±ê°’ í—ˆìš©
    // ê²°ì •ë¡ ì  ëª¨ë“œì—ì„œëŠ” ëª¨ë“  í† í°ì„ í—ˆìš© (volume ì—†ì–´ë„ OK)
    let eligible = true;
    let skipReason: string | undefined;
    
    // Soft gate: volume ì—†ì„ ë•Œë§Œ ê²½ê³ , ì°¨ë‹¨í•˜ì§€ ì•ŠìŒ
    if (vol === 0) {
      skipReason = 'No volume data (fallback allowed)';
      console.log(`âš ï¸ [SOFT GATE] "${candidate.text}" â†’ PASSED (no volume, fallback mode)`);
    } else {
      console.log(`âœ… [SOFT GATE] "${candidate.text}" â†’ PASSED (volume: ${vol})`);
    }
    
    return {
      ...candidate,
      totalScore,
      adScore,
      eligible,
      skipReason
    };
  });
  
  // Count gate filtering
  stats.gateFiltered = enrichedCandidates.filter((c: Candidate) => !c.eligible).length;
  console.log(`ğŸš« [v17 Pipeline] Gate filtered ${stats.gateFiltered} candidates (deterministic mode)`);
  
  // Step 5: Ranking checks
  console.log(`ğŸ” [v17 Pipeline] Checking SERP rankings for ${enrichedCandidates.length} candidates`);
  const rankedCandidates: Candidate[] = [];
  
  for (const candidate of enrichedCandidates) {
    let rank: number | null = null;
    
    // Only check rank for eligible candidates in hard mode
    if (candidate.eligible || cfg.adscore.mode === 'soft') {
      try {
        rank = await serpScraper.checkKeywordRankingInMobileNaver(candidate.text, `https://blog.naver.com/${blogId}`);
        console.log(`   ğŸ“Š [Rank Check] "${candidate.text}" â†’ rank ${rank || 'NA'}`);
      } catch (error) {
        console.error(`   âŒ [Rank Check] Failed for "${candidate.text}":`, error);
      }
    }
    
    rankedCandidates.push({
      ...candidate,
      rank,
    });
  }
  
  // Step 6: â˜… ìµœì¢… ê·œì¹™ ì ìš© (T1=ë‹¨ì¼ + T2/T3/T4=ë¹…ê·¸ë¨)
  console.log(`ğŸ¯ [v17 Final Rules] Applying final tier rules: T1=single + T2/T3/T4=bigrams...`);
  
  // Helper functions from vFinal
  const hasMatjip = (tokens: string[]): boolean => tokens.some(t => t.includes('ë§›ì§‘'));
  const hasLocal = (tokens: string[]): boolean => {
    const localPattern = /(ì„œìš¸|ë¶€ì‚°|ì¸ì²œ|ëŒ€êµ¬|ëŒ€ì „|ê´‘ì£¼|ìš¸ì‚°|ì„¸ì¢…|ê²½ê¸°|ê°•ì›|ì¶©ë¶|ì¶©ë‚¨|ì „ë¶|ì „ë‚¨|ê²½ë¶|ê²½ë‚¨|ì œì£¼|[ê°€-í£]+(ì‹œ|êµ°|êµ¬|ë™|ì|ë©´|ë¦¬))/;
    return tokens.some(t => localPattern.test(t));
  };
  
  const pickBestSecondary = (allTokens: string[], candidatesWithVolume: Candidate[], t1Text: string): string => {
    console.log(`ğŸ” [pickBestSecondary] Finding best secondary for T1: "${t1Text}"`);
    
    // ìš°ì„ ìˆœìœ„ 1: ë§›ì§‘ (ìˆìœ¼ë©´ ë¬´ì¡°ê±´)
    if (hasMatjip(allTokens)) {
      console.log(`   âœ… Found ë§›ì§‘ in tokens - using as bestSecondary`);
      return 'ë§›ì§‘';
    }
    
    // ìš°ì„ ìˆœìœ„ 2: ë¡œì»¬ (ìˆìœ¼ë©´)
    const localTokens = allTokens.filter(t => hasLocal([t]));
    if (localTokens.length > 0) {
      console.log(`   âœ… Found local token: "${localTokens[0]}" - using as bestSecondary`);
      return localTokens[0];
    }
    
    // ìš°ì„ ìˆœìœ„ 3: ì¡°íšŒëŸ‰ 2ìœ„ (T1 ì œì™¸)
    const volumeSorted = candidatesWithVolume
      .filter(c => c.text !== t1Text && (c.volume || 0) > 0)
      .sort((a, b) => (b.volume || 0) - (a.volume || 0));
    
    if (volumeSorted.length > 0) {
      console.log(`   âœ… Found volume #2: "${volumeSorted[0].text}" (volume: ${volumeSorted[0].volume}) - using as bestSecondary`);
      return volumeSorted[0].text;
    }
    
    // Fallback: ë‹¤ìŒ í† í°
    const fallback = allTokens.find(t => t !== t1Text);
    console.log(`   âš ï¸ Fallback to next token: "${fallback || 'none'}"`);
    return fallback || '';
  };
  
  const makeBigram = (token1: string, token2: string): string => token2 ? `${token1} ${token2}` : token1;
  
  // â˜… T1 ì„ ì •: ë‹¨ì¼ í† í° ì¤‘ ìµœê³  ë³¼ë¥¨ (ë§›ì§‘/ë¡œì»¬ ë‹¨ë… ì œì™¸)
  const singleCandidates = rankedCandidates.filter(c => 
    c.eligible && 
    !c.compound && 
    c.text !== 'ë§›ì§‘' && 
    !hasLocal([c.text])
  ).sort((a, b) => (b.volume || 0) - (a.volume || 0));
  
  // â˜… í‹°ì–´ ë³€ìˆ˜ ì„ ì–¸ (ìŠ¤ì½”í”„ ë¬¸ì œ í•´ê²°)
  let tiers: Tier[] = [];
  
  if (singleCandidates.length === 0) {
    console.log(`âŒ [v17 Final Rules] No valid single tokens for T1`);
    tiers = [];
  } else {
    const T1 = singleCandidates[0];
    console.log(`ğŸ¯ [T1 Final] "${T1.text}" (volume: ${T1.volume || 0})`);
    
    // â˜… T2/T3/T4 ë¹…ê·¸ë¨ ìƒì„± (Architect ìš”êµ¬ì‚¬í•­: ì‹¤ì œ pairwise ì¡°í•©)
    const titleTokens = extractTitleTokens(title); // ì œëª©ì—ì„œ ì§ì ‘ í† í° ì¶”ì¶œ
    console.log(`ğŸ”§ [Bigram Generation] Title tokens: ${titleTokens.join(', ')}`);
    
    // pairwise ë¹…ê·¸ë¨ ìƒì„± (Architect ê¶Œì¥: bigrams = pairwise(toks))
    const bigrams: string[] = [];
    for (let i = 0; i < titleTokens.length; i++) {
      for (let j = i + 1; j < titleTokens.length; j++) {
        const bigram = `${titleTokens[i]} ${titleTokens[j]}`;
        if (!bigrams.includes(bigram)) {
          bigrams.push(bigram);
        }
      }
    }
    console.log(`ğŸ”§ [Bigram Generation] Generated ${bigrams.length} bigrams: ${bigrams.slice(0, 3).join(', ')}...`);
    
    // T1ì´ í¬í•¨ëœ ë¹…ê·¸ë¨ë§Œ í•„í„°ë§ (T1 + ë‹¤ë¥¸ í† í° ì¡°í•©)
    const t1Bigrams = bigrams.filter(bg => bg.includes(T1.text));
    console.log(`ğŸ¯ [T1 Bigrams] Filtered ${t1Bigrams.length} bigrams containing T1: ${t1Bigrams.slice(0, 3).join(', ')}...`);
    
    // ìš°ì„ ìˆœìœ„: ë§›ì§‘ > ë¡œì»¬ > ì•ŒíŒŒë²³ ìˆœ
    const prioritizeBigram = (bg: string): number => {
      if (bg.includes('ë§›ì§‘')) return 3;
      if (hasLocal(bg.split(' '))) return 2;
      return 1;
    };
    
    const sortedT1Bigrams = t1Bigrams.sort((a, b) => {
      const priorityDiff = prioritizeBigram(b) - prioritizeBigram(a);
      return priorityDiff !== 0 ? priorityDiff : a.localeCompare(b);
    });
    
    const t2Text = sortedT1Bigrams[0] || null;
    const t3Text = sortedT1Bigrams[1] || null;
    const t4Text = sortedT1Bigrams[2] || null;
    
    console.log(`ğŸ¯ [T2 Final] "${t2Text}"`);
    console.log(`ğŸ¯ [T3 Final] "${t3Text || 'none'}"`);
    console.log(`ğŸ¯ [T4 Final] "${t4Text || 'none'}"`);
    
    // â˜… ë¹…ê·¸ë¨ ì„¼ë””ë°ì´íŠ¸ ìƒì„±
    const createBigramCandidate = (text: string, baseVolume: number = 0): Candidate => ({
      text,
      frequency: 1,
      position: 0,
      length: text.length,
      compound: true,
      volume: baseVolume, // ì˜ˆìƒ ë³¼ë¥¨ (SearchAdsì—ì„œ ì—…ë°ì´íŠ¸ í•„ìš”)
      totalScore: 0.7 * Math.log10(Math.max(1, baseVolume)) * 25,
      adScore: 0.5, // Mock
      eligible: true,
      rank: null
    });
    
    tiers = [
      { tier: 1, candidate: T1, score: T1.totalScore || 0 }
    ];
    
    if (t2Text) {
      const t2Candidate = createBigramCandidate(t2Text, T1.volume || 0);
      tiers.push({ tier: 2, candidate: t2Candidate, score: t2Candidate.totalScore || 0 });
    }
    if (t3Text) {
      const t3Candidate = createBigramCandidate(t3Text, Math.floor((T1.volume || 0) * 0.5));
      tiers.push({ tier: 3, candidate: t3Candidate, score: t3Candidate.totalScore || 0 });
    }
    if (t4Text) {
      const t4Candidate = createBigramCandidate(t4Text, Math.floor((T1.volume || 0) * 0.3));
      tiers.push({ tier: 4, candidate: t4Candidate, score: t4Candidate.totalScore || 0 });
    }
  } // â˜… else ë¸”ë¡ ë‹«ê¸°
  
  console.log(`ğŸ¯ [v17 Deterministic] Created ${tiers.length} deterministic tiers (max 4)`);
  
  // Step 7: Auto-fill if enabled and needed (â˜… 4ê°œ ì œí•œ ê°•ì œ)
  let finalTiers = [...tiers];  // âœ… Create copy to avoid mutation
  const MAX_TIERS_HARD_CAP = 4; // â˜… í‚¤ì›Œë“œ í­ì¦ ë°©ì§€ë¥¼ ìœ„í•œ í•˜ë“œ ìº¡
  const targetTiers = Math.min(cfg.phase2.tiersPerPost || 4, MAX_TIERS_HARD_CAP);
  
  if (cfg.features.tierAutoFill && tiers.length < targetTiers) {
    console.log(`ğŸ”§ [v17 Pipeline] Auto-filling tiers (${tiers.length}/${targetTiers}, hard cap: ${MAX_TIERS_HARD_CAP})`);
    
    // Simple auto-fill: add remaining ELIGIBLE candidates only (â˜… Gate ì •ì±… ì¤€ìˆ˜)
    const usedTexts = new Set(tiers.map((t: Tier) => t.candidate?.text).filter(Boolean));
    const remainingCandidates = rankedCandidates.filter(c => 
      !usedTexts.has(c.text) && c.eligible // â˜… ì ê²© í›„ë³´ë§Œ ì‚¬ìš©
    );
    
    // Fill remaining slots (â˜… í•˜ë“œ ìº¡ ì¤€ìˆ˜)
    while (finalTiers.length < targetTiers && remainingCandidates.length > 0) {
      const candidate = remainingCandidates.shift()!;
      finalTiers.push({
        tier: finalTiers.length + 1,
        candidate,
        score: candidate.totalScore || 0,
      });
      stats.tiersAutoFilled++;
    }
    
    console.log(`âœ… [v17 Pipeline] Auto-filled ${stats.tiersAutoFilled} tiers`);
  }
  
  // Step 8: Save to postTierChecks (eligible/adscore/skip_reason í•¨ê»˜ ì €ì¥)
  console.log(`ğŸ’¾ [v17 Pipeline] Saving ${finalTiers.length} tiers to database`);
  
  for (const tier of finalTiers) {
    console.log(`ğŸ” [v17 Debug] Tier ${tier.tier}:`, JSON.stringify(tier, null, 2));
    
    const candidate = tier.candidate;
    if (!candidate) {
      console.error(`âŒ [v17 Pipeline] Tier ${tier.tier} has no candidate object!`);
      continue;
    }
    
    if (!candidate.text) {
      console.error(`âŒ [v17 Pipeline] Tier ${tier.tier} candidate has no text!`);
      continue;
    }
    
    const normalizedText = candidate.text.normalize('NFKC').toLowerCase().replace(/[\s\-_.]/g, '');
    const isRelated = inputKeyword.normalize('NFKC').toLowerCase().replace(/[\s\-_.]/g, '').includes(normalizedText) ||
                     title.toLowerCase().includes(candidate.text.toLowerCase());
    
    try {
      await db.insert(postTierChecks).values({
        jobId,
        inputKeyword,
        blogId,
        postId: String(postId), // âœ… Convert to string
        postTitle: title,
        tier: tier.tier,
        textSurface: candidate.text,
        textNrm: normalizedText,
        volume: candidate.volume ?? null, // âœ… null ì €ì¥ (0 ë°©ì§€)
        rank: candidate.rank,
        score: tier.score,
        related: isRelated,
        // v17 ì¶”ê°€: Gate ì •ë³´
        eligible: candidate.eligible ?? true,
        adscore: candidate.adScore, // âœ… Lowercase column name
        skipReason: candidate.skipReason,
      });
    } catch (insertError) {
      console.error(`âŒ [v17 Pipeline] Insert failed for tier ${tier.tier}:`, insertError);
      throw insertError;
    }
    
    console.log(`   ğŸ’¾ [Tier ${tier.tier}] "${candidate.text}" â†’ score ${tier.score}, rank ${candidate.rank || 'NA'}, eligible ${candidate.eligible}`);
  }
  
  // Prepare return format
  const result: V17PipelineResult = {
    tiers: finalTiers.map(tier => ({
      tier: tier.tier,
      text: tier.candidate.text,
      volume: tier.candidate.volume ?? null,
      rank: tier.candidate.rank ?? null,
      score: tier.score,
      adScore: tier.candidate.adScore,
      eligible: tier.candidate.eligible,
      skipReason: tier.candidate.skipReason,
    })),
    stats,
  };
  
  console.log(`âœ… [v17 Pipeline] Completed - Generated ${result.tiers.length} tiers with scores`);
  return result;
}

/**
 * ì„œë²„ì—ì„œ ì ìˆ˜ ê³„ì‚° (ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ 3ë‹¨ê³„)
 */
export function calculateTotalScore(candidate: Candidate, cfg: any): number {
  // volumeScale = min(100, log10(max(1, volume))*25);
  const volume = candidate.volume || 1;
  const volumeScale = Math.min(100, Math.log10(Math.max(1, volume)) * 25);
  
  // contentScore = 0.5*freq + 0.3*pos + 0.2*len; (ë‚´ë¶€ ê°€ì¤‘ì¹˜)
  const freq = candidate.frequency || 0;
  const pos = 1 / Math.max(1, candidate.position || 1); // Position penalty
  const len = Math.min(1, (candidate.length || 1) / 20); // Length normalization
  const contentScore = 0.5 * freq + 0.3 * pos + 0.2 * len;
  
  // totalScore = 0.7*volumeScale + 0.3*contentScore; (cfg.weightsë¡œ ì¡°ì •)
  const totalScore = (cfg.weights?.volume || 0.7) * volumeScale + (cfg.weights?.content || 0.3) * contentScore * 100;
  
  return Math.round(totalScore * 100) / 100; // ì†Œìˆ˜ì  2ìë¦¬
}

/**
 * v17 ê²°ê³¼ ì¡°ë¦½ ë° ì €ì¥ì„ í¬í•¨í•œ SERP ë¶„ì„ ë˜í¼
 */
export async function processSerpAnalysisJobWithV17Assembly(
  jobId: string,
  keywords: string[],
  minRank: number,
  maxRank: number,
  postsPerBlog: number,
  titleExtract: boolean,
  lkOptions: any
) {
  try {
    console.log(`ğŸš€ [v17 Assembly] Starting for job ${jobId}`);
    
    // 1) v17 ì„¤ì • ë¡œë“œ
    const cfg = await getAlgoConfig();
    
    // 2) ì‹¤ì œ SERP ë¶„ì„ ì‹¤í–‰ (v17 deterministic ëª¨ë“œ)
    console.log(`ğŸ¯ [v17-DETERMINISTIC] Executing real SERP analysis for job ${jobId}`);
    
    // âœ… ì‹¤ì œ processSerpAnalysisJob í•¨ìˆ˜ ì§ì ‘ ì •ì˜ (circular import ë°©ì§€)
    const processSerpAnalysisJob = (await import("../routes")).processSerpAnalysisJob;
    
    await new Promise<void>((resolve, reject) => {
      try {
        // â˜… ì‹¤ì œ SERP ë¶„ì„ ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©í•˜ë˜ v17 ëª¨ë“œ)
        processSerpAnalysisJob(jobId, keywords, minRank, maxRank, postsPerBlog, titleExtract, {
          ...lkOptions,
          v17Mode: true,
          deterministic: true  // âœ… deterministic í”Œë˜ê·¸ ì „ë‹¬
        });
        
        // ë¹„ë™ê¸° ì™„ë£Œ ëŒ€ê¸° (ì‹¤ì œ ë¶„ì„ì´ ëë‚  ë•Œê¹Œì§€)
        setTimeout(() => {
          console.log(`âœ… [v17-DETERMINISTIC] SERP analysis completed for ${jobId}`);
          resolve();
        }, 5000); // 5ì´ˆ ëŒ€ê¸° (ì‹¤ì œ ë¶„ì„ ì‹œê°„ ê³ ë ¤)
        
      } catch (error) {
        console.error(`âŒ [v17-DETERMINISTIC] SERP analysis failed for ${jobId}:`, error);
        reject(error);
      }
    });
    
    // 3) v17 tier ë°ì´í„° ìˆ˜ì§‘ ë° ì¡°ë¦½
    console.log(`ğŸ”§ [v17 Assembly] Collecting tier data for ${jobId}`);
    
    // â˜… ì‹¤ì œ DBì—ì„œ tier ë°ì´í„° ìˆ˜ì§‘
    const { db } = await import("../db");
    const { postTierChecks, discoveredBlogs } = await import("../../shared/schema");
    const { eq } = await import("drizzle-orm");
    
    const tierData = await db.select().from(postTierChecks).where(eq(postTierChecks.jobId, jobId));
    const blogData = await db.select().from(discoveredBlogs).where(eq(discoveredBlogs.jobId, jobId));
    
    console.log(`ğŸ“Š [v17 Assembly] Found ${tierData.length} tier records, ${blogData.length} blogs`);
    
    // â˜… assembleResultsê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const tiers: any[] = tierData.map(tier => ({
      tier: tier.tier,
      keywords: [{
        inputKeyword: tier.inputKeyword,
        text: tier.textSurface,
        volume: tier.volume
      }],
      blog: {
        blogId: tier.blogId,
        blogName: blogData.find(b => b.blogId === tier.blogId)?.blogName || tier.blogId,
        blogUrl: blogData.find(b => b.blogId === tier.blogId)?.blogUrl || ''
      },
      post: {
        title: tier.postTitle
      },
      candidate: {
        text: tier.textSurface,
        volume: tier.volume,
        rank: tier.rank,
        totalScore: tier.score || 0, // â˜… ìƒˆë¡œ ì¶”ê°€ëœ score í•„ë“œ ì‚¬ìš©
        adScore: tier.adscore,
        eligible: tier.eligible,
        skipReason: tier.skipReason
      },
      score: tier.score || 0 // â˜… ë ˆê±°ì‹œ í˜¸í™˜ì„±
    }));
    
    // 4) ê²°ê³¼ ì¡°ë¦½
    const { assembleResults } = await import("../phase2/helpers");
    const payload = assembleResults(jobId, tiers, cfg);
    
    // 5) ê²°ê³¼ë¥¼ DBì— ì €ì¥
    const { MemStorage } = await import("../storage");  
    const storage = new MemStorage();
    
    await storage.updateSerpJob(jobId, {
      status: "completed",
      progress: 100,
      currentStep: "completed", 
      currentStepDetail: "v17 pipeline analysis completed successfully",
      results: payload
    });
    
    console.log(`ğŸ‰ [v17 Assembly] Completed for job ${jobId}`);
    
  } catch (error) {
    console.error(`âŒ [v17 Assembly] Error for job ${jobId}:`, error);
    
    // ì—ëŸ¬ ë°œìƒ ì‹œ legacy fallback ì‹¤í–‰
    console.log(`ğŸ”„ [v17 Assembly] Falling back to legacy for ${jobId}`);
    throw error; // Re-throw to trigger fallback in routes.ts
  }
}