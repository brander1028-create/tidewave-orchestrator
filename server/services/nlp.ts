import { listKeywords } from '../store/keywords';

export interface KeywordCandidate {
  keyword: string;
  frequency: number;
  score: number;
  volume?: number;
  grade?: string;
  isFromDB?: boolean;
}

export class NLPService {
  private stopWords = new Set([
    // Korean stopwords
    'Ïù¥', 'Í∑∏', 'Ï†Ä', 'Í≤É', 'Îì§', 'Ïùò', 'Í∞Ä', 'ÏùÑ', 'Î•º', 'Ïóê', 'ÏôÄ', 'Í≥º', 'ÎèÑ', 'Îßå', 'ÎèÑ', 'ÏóêÏÑú', 'ÏúºÎ°ú', 'Î°ú', 'Ïù¥Îã§', 'ÏûàÎã§', 'ÌïòÎã§',
    'Í∑∏Î¶¨Í≥†', 'Í∑∏Îü∞Îç∞', 'ÌïòÏßÄÎßå', 'Í∑∏Îü¨ÎÇò', 'ÎòêÌïú', 'Îòê', 'Í∑∏ÎûòÏÑú', 'Îî∞ÎùºÏÑú', 'Ï¶â', 'ÏòàÎ•º Îì§Ïñ¥', 'ÎïåÎ¨∏Ïóê', 'ÏúÑÌï¥', 'ÌÜµÌï¥', 'ÎåÄÌï¥',
    'Ï†ïÎßê', 'Îß§Ïö∞', 'ÎÑàÎ¨¥', 'ÏïÑÏ£º', 'Ï†ïÎßêÎ°ú', 'Ìï≠ÏÉÅ', 'Îäò', 'ÏûêÏ£º', 'Í∞ÄÎÅî', 'ÎïåÎ°úÎäî', 'Ïù¥Î≤à', 'Îã§Ïùå', 'ÏßÄÎÇú', 'Ïò§Îäò', 'Ïñ¥Ï†ú', 'ÎÇ¥Ïùº',
    'Ïó¨Í∏∞', 'Í±∞Í∏∞', 'Ï†ÄÍ∏∞', 'Ïù¥Í≥≥', 'Í∑∏Í≥≥', 'Ï†ÄÍ≥≥', 'ÏúÑ', 'ÏïÑÎûò', 'Ïïû', 'Îí§', 'ÏòÜ', 'ÏÇ¨Ïù¥',
    // Common blog words
    'Î∏îÎ°úÍ∑∏', 'Ìè¨Ïä§ÌåÖ', 'Î¶¨Î∑∞', 'ÌõÑÍ∏∞', 'Ï∂îÏ≤ú', 'ÏÜåÍ∞ú', 'Ï†ïÎ≥¥', 'Í≥µÏú†', 'Ïù¥ÏïºÍ∏∞', 'Í≤ΩÌóò', 'Î∞©Î≤ï', 'ÏÉùÍ∞Å', 'ÎäêÎÇå',
    'ÏÇ¨ÏßÑ', 'Ïù¥ÎØ∏ÏßÄ', 'ÏòÅÏÉÅ', 'ÎèôÏòÅÏÉÅ', 'ÎßÅÌÅ¨', 'ÎåìÍ∏Ä', 'Ï¢ãÏïÑÏöî', 'Íµ¨ÎèÖ', 'ÌåîÎ°úÏö∞',
    // Numbers and punctuation patterns
    ...Array.from({length: 100}, (_, i) => i.toString()),
  ]);

  /**
   * Clean and normalize text for processing
   */
  private cleanText(text: string): string {
    return text
      .replace(/<[^>]*>/g, '') // Remove HTML tags
      .replace(/[^\w\sÍ∞Ä-Ìû£]/g, ' ') // Keep only Korean, alphanumeric and spaces
      .replace(/\s+/g, ' ') // Normalize whitespace
      .trim()
      .toLowerCase();
  }

  /**
   * Extract n-grams from tokenized text
   * Supports 1-gram, 2-gram, and 3-gram extraction as specified
   */
  private extractNgrams(text: string, n: number): string[] {
    const words = text.split(' ').filter(word => 
      word.length >= 2 && 
      !this.stopWords.has(word) &&
      !/^\d+$/.test(word) // Skip pure numbers
    );
    
    const ngrams: string[] = [];
    
    for (let i = 0; i <= words.length - n; i++) {
      const ngram = words.slice(i, i + n).join(' ');
      if (ngram.length >= 2) {
        ngrams.push(ngram);
      }
    }
    
    return ngrams;
  }

  /**
   * Extract keywords using n-gram (1-3) approach from titles with keyword DB integration
   * This implements n-gram keyword extraction enhanced with existing keyword database
   */
  async extractKeywords(titles: string[]): Promise<KeywordCandidate[]> {
    console.log(`üî§ Starting n-gram keyword extraction from ${titles.length} titles`);
    
    // Get keyword volume map from database
    console.log(`üîç Fetching keywords from database...`);
    const dbKeywords = await listKeywords({ excluded: false, orderBy: 'raw_volume', dir: 'desc' });
    const keywordVolumeMap: Record<string, { volume: number; grade: string }> = {};
    
    dbKeywords.forEach(keyword => {
      // Normalize DB keyword text using the same cleanText logic for better matching
      const normalizedText = this.cleanText(keyword.text);
      keywordVolumeMap[normalizedText] = {
        volume: keyword.raw_volume || keyword.volume || 0,
        grade: keyword.grade || 'C'
      };
    });
    
    const dbKeywordCount = dbKeywords.length;
    console.log(`üìä Loaded ${dbKeywordCount} keywords from database`);
    
    const keywordFreq = new Map<string, number>();
    
    // Clean titles and extract text
    const cleanedTitles = titles.map(title => this.cleanText(title));
    console.log(`üìù Cleaned titles: ${cleanedTitles.slice(0, 3).join(', ')}...`);
    
    // Extract 1-grams, 2-grams, and 3-grams as specified
    for (const title of cleanedTitles) {
      // 1-grams (single words)
      const unigrams = this.extractNgrams(title, 1);
      // 2-grams (word pairs)
      const bigrams = this.extractNgrams(title, 2);
      // 3-grams (word triplets)
      const trigrams = this.extractNgrams(title, 3);
      
      // Count frequency with different weights
      // Higher weight for longer phrases as they're more specific
      [...unigrams, ...bigrams, ...trigrams].forEach(ngram => {
        const weight = ngram.split(' ').length; // 1, 2, or 3
        keywordFreq.set(ngram, (keywordFreq.get(ngram) || 0) + weight);
      });
    }
    
    // Calculate relevance scores with DB integration
    const candidates: KeywordCandidate[] = [];
    const totalTitles = titles.length;
    
    for (const [keyword, frequency] of Array.from(keywordFreq.entries())) {
      if (frequency >= 2) { // Filter out keywords that appear only once
        // Document frequency: how many titles contain this keyword
        const documentFreq = cleanedTitles.filter(title => 
          title.includes(keyword)
        ).length;
        
        // Check if keyword exists in database
        const dbKeywordInfo = keywordVolumeMap[keyword];
        const isFromDB = !!dbKeywordInfo;
        
        // Base score calculation
        let score = Math.round(
          (frequency * 10) + // Base frequency score
          (keyword.split(' ').length * 5) + // Length bonus
          (documentFreq / totalTitles * 20) // Document frequency bonus
        );
        
        // Boost score for keywords found in database
        if (isFromDB) {
          const volumeBoost = Math.min(dbKeywordInfo.volume / 1000, 50); // Volume-based bonus (max 50)
          const gradeBoost = dbKeywordInfo.grade === 'A' ? 30 : dbKeywordInfo.grade === 'B' ? 20 : 10;
          score += Math.round(volumeBoost + gradeBoost);
          
          console.log(`üéØ DB keyword found: "${keyword}" (volume: ${dbKeywordInfo.volume}, grade: ${dbKeywordInfo.grade}, boost: +${Math.round(volumeBoost + gradeBoost)})`);
        }
        
        candidates.push({
          keyword,
          frequency,
          score,
          volume: dbKeywordInfo?.volume,
          grade: dbKeywordInfo?.grade,
          isFromDB,
        });
      }
    }
    
    // Sort by score and return top candidates
    const sortedCandidates = candidates
      .sort((a, b) => b.score - a.score)
      .slice(0, 50); // Return top 50 keywords
    
    console.log(`‚úÖ N-gram extraction complete: ${sortedCandidates.length} keyword candidates found`);
    console.log(`üèÜ Top 5 keywords: ${sortedCandidates.slice(0, 5).map(k => `${k.keyword}(${k.score})`).join(', ')}`);
    
    return sortedCandidates;
  }

  /**
   * Get top N keywords from candidates
   */
  getTopKeywords(candidates: KeywordCandidate[], limit = 20): KeywordCandidate[] {
    const topKeywords = candidates.slice(0, limit);
    console.log(`üìä Selected top ${topKeywords.length} keywords for analysis`);
    return topKeywords;
  }
}

export const nlpService = new NLPService();